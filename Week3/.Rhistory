# Unit 3, Recitation
# Video 2
# Read in data
polling = read.csv("PollingData.csv")
str(polling)
table(polling$Year)
summary(polling)
# Install and load mice package
install.packages("mice")
library(mice)
# Multiple imputation
simple = polling[c("Rasmussen", "SurveyUSA", "PropR", "DiffCount")]
summary(simple)
set.seed(144)
imputed = complete(mice(simple))
summary(imputed)
polling$Rasmussen = imputed$Rasmussen
polling$SurveyUSA = imputed$SurveyUSA
summary(polling)
# Video 3
# Subset data into training set and test set
Train = subset(polling, Year == 2004 | Year == 2008)
Test = subset(polling, Year == 2012)
# Smart Baseline
table(Train$Republican)
sign(20)
sign(-10)
sign(0)
table(sign(Train$Rasmussen))
table(Train$Republican, sign(Train$Rasmussen))
# Video 4
# Multicollinearity
cor(Train)
str(Train)
cor(Train[c("Rasmussen", "SurveyUSA", "PropR", "DiffCount", "Republican")])
# Logistic Regression Model
mod1 = glm(Republican~PropR, data=Train, family="binomial")
summary(mod1)
# Training set predictions
pred1 = predict(mod1, type="response")
table(Train$Republican, pred1 >= 0.5)
# Two-variable model
mod2 = glm(Republican~SurveyUSA+DiffCount, data=Train, family="binomial")
pred2 = predict(mod2, type="response")
table(Train$Republican, pred2 >= 0.5)
summary(mod2)
# Video 5
# Smart baseline accuracy
table(Test$Republican, sign(Test$Rasmussen))
# Test set predictions
TestPrediction = predict(mod2, newdata=Test, type="response")
table(Test$Republican, TestPrediction >= 0.5)
# Analyze mistake
subset(Test, TestPrediction >= 0.5 & Republican == 0)
q()
songs <- read.csv("songs.csv")
which.max(songs$tempo)
songs$songtitle[6206]
songsTrain = subset(songs,songs$year <= 2009)
songsTest = subset(songs,songs$year == 2010)
nonvars = c("year", "songtitle", "artistname", "songID", "artistID")
SongsTrain = SongsTrain[ , !(names(SongsTrain) %in% nonvars) ]
songsTrain = SongsTrain[ , !(names(SongsTrain) %in% nonvars) ]
SongsTrain = subset(songs,songs$year <= 2009)
SongsTest = subset(songs,songs$year == 2010)
SongsTrain = SongsTrain[ , !(names(SongsTrain) %in% nonvars) ]
SongsTest = SongsTest[ , !(names(SongsTest) %in% nonvars) ]
model1 <- glm(Top10 ~ . ,data = SongsTrain,family = binomial)
summary(model1)
cor(SongsTrain$loudness,SongsTrain$energy)
SongsLog2 = glm(Top10 ~ . - loudness, data=SongsTrain, family=binomial)
summary(SongsLog2)
SongsLog3 = glm(Top10 ~ . - energy, data=SongsTrain, family=binomial)
summary(SongsLog3)
pred <- predict(SongsLog3,type = response)
pred <- predict(SongsLog3,type = "response")
table(SongsTrain$Top10,pred >=0.45)
(5953+248)/(5953+188+812+248)
# Unit 3, The Framingham Heart Study
# Video 3
# Read in the dataset
framingham = read.csv("framingham.csv")
# Look at structure
str(framingham)
# Load the library caTools
library(caTools)
# Randomly split the data into training and testing sets
set.seed(1000)
split = sample.split(framingham$TenYearCHD, SplitRatio = 0.65)
# Split up the data using subset
train = subset(framingham, split==TRUE)
test = subset(framingham, split==FALSE)
# Logistic Regression Model
framinghamLog = glm(TenYearCHD ~ ., data = train, family=binomial)
summary(framinghamLog)
# Predictions on the test set
predictTest = predict(framinghamLog, type="response", newdata=test)
# Confusion matrix with threshold of 0.5
table(test$TenYearCHD, predictTest > 0.5)
# Accuracy
# Accuracy
(1069+11)/(1069+6+187+11)
# Baseline accuracy
(1069+6)/(1069+6+187+11)
table(SongsTrain$Top10,pred >=0.45)
table(SongsTrain$Top10,pred >0.45)
(5953+188)/(5953+188+812+248)
pred <- predict(SongsLog3,type = "response",newdata = SongsTest)
table(SongsTest$Top10,pred >0.45)
(309+19)/45
(309+19)/(45+19+309)
(309+5)/(45+19+309)
19/(59)
309/314
rm(list=ls())
parole <- read.csv("parole.csv")
summary(parole)
str(parole)
table(parole$violator)
levels(parole)
levels(parole$male)
parole$male <- as.factor(parole$male)
parole$state <- as.factor(parole$state)
parole$race <- as.factor(parole$race)
parole$crime <- as.factor(parole$crime)
parole$violator <- as.factor(parole$violator)
summary(paroel)
summary(parole)
parole <- read.csv("parole.csv")
parole$crime <- as.factor(parole$crime)
parole$state <- as.factor(parole$state)
set.seed
set.seed(144)
library(caTools)
split = sample.split(parole$violator,SplitRatio = 0.7)
train = subset(parole,split=TRUE)
test = subset(parole,split = FALSE)
train = subset(parole,split==TRUE)
test = subset(parole,split == FALSE)
mod1 <- glm(violator~.,family = binomial,data = train)
summary(mod1)
q()
summary(mod1)
